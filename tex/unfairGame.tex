Looking at real data, it can be seen that in real life higher capitals are distributed following a power law, instead of an exponential.
The power law goes to zero slower than the exponential, so this distribution seems more fair than what we have hypothesized in our previous model.
In order to reproduce this behavior we have to introduce some unfairness in the model.
The best way to do so is to introduce a preferential attachment, which means that individuals who have more money have a higher probability of earning more.
In this case, the richer (poorer) individuals have an attractive property, which allows them to earn (lose) more money as they get richer (poorer). \\
To implement this preferential attachment we can change the probabilities of winning and losing in a way that favors the individuals with more money.
If $\epsilon$ is the probability that the richer individual wins then $\bar{\epsilon} = 1 - \epsilon$ is the probability that it's the poorer who wins, we can define them as follows:
\begin{equation}
	\varepsilon = \frac{r + 1}{r + p + 2} \ \ \ \ \ \ \ \  \bar{\varepsilon} = \frac{p + 1}{r + p + 2}
	\label{eq:prefAttach}
\end{equation}
where $r$ is the capital of the richer one and $p$ the capital of the poorer.
We notice that using these probabilities even an individual without any money has a winning chance.
Using the same values of $N$ and $\alpha$ as before, we now let the system evolve $4 \times 10^5$ times using the probabilities defined in the relation (\ref{eq:prefAttach}).
\begin{figure}[H]
    \centering
    \scalebox{.7}{\input{./img/pow.pgf}}
    \caption{\emph{Frequency of agents related to their capital.}}
    \label{fig:prefAttach}
\end{figure}
In this case, as shown in Fig. \ref{fig:prefAttach}, the distribution is not exponential anymore but a power law.
We expected this: considering a dependence on the actual capital to the probability means that we actually added \emph{memory} to the dynamics.
In fact, in a system with memory each time step is not independent of the previous ones.
\\Moreover, we expect this distribution to obey the Zipf's law, which is typical of preferential attachment phenomena.
Zipf's law states that the frequency of an event with rank $r$ has a power behavior \cite{zipf}:
\begin{equation}
    f(r) \sim r^b \ \ \ \ \ \ \ \ \ b \simeq -1
    \label{eq:zipf}
\end{equation}
The expected value of the $r$th ranked capital value $n_r$ is
\begin{equation*}
    \mathbb{E}(n_r)\sim r^b
\end{equation*}
This means there are $r$ variables with expected value greater or equal to $\mathbb{E}(n_r)$, so $\mathbb{P}(n \geq \mathbb{E}(n_r)) \sim r$.
Making the variable change $y=r^b$, which represents the wealth, we obtain the cumulative distribution
\begin{equation*}
    \mathbb{P}(n \geq y) \sim y^{\frac{1}{b}}
\end{equation*}
In order to get the pdf, we take the derivative with respect to $n$
\begin{equation}
    \mathbb{P}(n = y) \equiv f(y) \sim y^{\frac{1}{b} - 1}
    \label{eq:paretoPDF}
\end{equation}
\\Fitting the data with a law of the type in Eq. (\ref{eq:paretoPDF}) we expect the total exponent $a \equiv \frac{1}{b} - 1$ to be $\simeq -2$.
The fit gives us the value $a = -1.83 \pm 0.08$, compatible with the hypothesis, that also confirms that the Zipf's behavior is well reproduced with $b = -1.22 \pm 0.11 \simeq -1$.
However, this model fits well only on the tail of the real distribution and does not well reproduce the lower capitals. \\ \\
% conti di Bazzani
To derive the expression of Zipf's law, let's consider the ordered values of richness of the population, $\{x_i\}$. At this point we define a ranking distribution, which is the function that, given the position in the ordered data, gives the corresponding data value:
\begin{equation}
	f(i) = x_i	
\end{equation}
It's easy to understand that $i/N$ gives an estimate for the probability $\mathbb{P}\{x > x_i\}$. The cumulative distribution, which is defined as
$$
	p(x) = \mathbb{P}\{y \leq x\}
$$
can be written in terms of the inverse of the ranking distribution:
\begin{equation}
	1 - p(x) = \frac{i}{N} = \frac{f^{-1}(x)}{N} \ \rita \ p(x) = 1 - \frac{f^{-1}(x)}{N}	
\end{equation}
Recalling that the probability density function is defined as 
$$
	\frac{dp}{dx} = \rho(x)
$$
we find the following expression for the pdf:
\begin{equation}
	\rho(x) = -\frac{d}{dx} \left(\frac{f^{-1}(x)}{N}\right)	
\end{equation}
If now we take a ranking distribution of the type
$$
	f(i) = \frac{x_1}{i} \ \rita \ f^{-1}(x) = \frac{x_1}{x}	
$$
we find that the pdf is a power law with exponent $-2$:
\begin{equation}
	\rho(x) = -\frac{1}{N}\frac{d}{dx}\left(\frac{x_1}{x}\right) = \frac{x_1}{N}\frac{1}{x^2}	
\end{equation}
